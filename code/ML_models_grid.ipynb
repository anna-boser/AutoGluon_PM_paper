{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_models_grid.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPrIZrmKSq5R6sSyC6Llf9x",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anna-boser/AutoGluon_PM_paper/blob/main/code/ML_models_grid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vJ-cgIDK6zvf",
        "outputId": "63f30e54-ef5a-40b4-d2b0-7a37c429887d"
      },
      "source": [
        "# Uninstall mkl for faster neural-network training time\n",
        "!pip uninstall -y mkl\n",
        "# Upgrade pip to ensure the latest package versions are available\n",
        "!pip install -U pip\n",
        "# Upgrade setuptools to be compatible with namespace packages\n",
        "!pip install -U setuptools\n",
        "!pip install -U \"mxnet<2.0.0\"\n",
        "# Install pre-release, frozen to a particual pre-release for stability\n",
        "!pip install --pre \"autogluon==0.0.16b20201214\"\n",
        "!pip install -U ipykernel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling mkl-2019.0:\n",
            "  Successfully uninstalled mkl-2019.0\n",
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/6f/43037c7bcc8bd8ba7c9074256b1a11596daa15555808ec748048c1507f08/pip-21.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 8.5MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-21.1.1\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (56.1.0)\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting mxnet<2.0.0\n",
            "  Downloading mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 46.9 MB 62 kB/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<2.0.0) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<2.0.0) (1.19.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.10)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting autogluon==0.0.16b20201214\n",
            "  Downloading autogluon-0.0.16b20201214-py3-none-any.whl (5.2 kB)\n",
            "Collecting autogluon.mxnet==0.0.16b20201214\n",
            "  Downloading autogluon.mxnet-0.0.16b20201214-py3-none-any.whl (31 kB)\n",
            "Collecting autogluon.vision==0.0.16b20201214\n",
            "  Downloading autogluon.vision-0.0.16b20201214-py3-none-any.whl (18 kB)\n",
            "Collecting autogluon.extra==0.0.16b20201214\n",
            "  Downloading autogluon.extra-0.0.16b20201214-py3-none-any.whl (22 kB)\n",
            "Collecting autogluon.tabular==0.0.16b20201214\n",
            "  Downloading autogluon.tabular-0.0.16b20201214-py3-none-any.whl (309 kB)\n",
            "\u001b[K     |████████████████████████████████| 309 kB 11.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from autogluon==0.0.16b20201214) (3.6.4)\n",
            "Collecting autogluon.core==0.0.16b20201214\n",
            "  Downloading autogluon.core-0.0.16b20201214-py3-none-any.whl (242 kB)\n",
            "\u001b[K     |████████████████████████████████| 242 kB 14.2 MB/s \n",
            "\u001b[?25hCollecting autogluon.text==0.0.16b20201214\n",
            "  Downloading autogluon.text-0.0.16b20201214-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 433 kB/s \n",
            "\u001b[?25hRequirement already satisfied: dask>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.19.5)\n",
            "Collecting ConfigSpace<=0.4.16\n",
            "  Downloading ConfigSpace-0.4.16.tar.gz (964 kB)\n",
            "\u001b[K     |████████████████████████████████| 964 kB 14.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn<0.24,>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (0.22.2.post1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (2.23.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.17.68-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 52.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (0.29.22)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (3.2.2)\n",
            "Requirement already satisfied: dill==0.3.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (0.3.3)\n",
            "Requirement already satisfied: pandas<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.1.5)\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.8.1-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.3)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (4.41.1)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (0.8.4)\n",
            "Collecting paramiko>=2.4\n",
            "  Downloading paramiko-2.7.2-py2.py3-none-any.whl (206 kB)\n",
            "\u001b[K     |████████████████████████████████| 206 kB 14.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy<1.5.0,>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.4.1)\n",
            "Collecting distributed>=2.6.0\n",
            "  Downloading distributed-2021.4.1-py3-none-any.whl (696 kB)\n",
            "\u001b[K     |████████████████████████████████| 696 kB 26.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (5.1.1)\n",
            "Collecting gluoncv==0.9.0\n",
            "  Downloading gluoncv-0.9.0-py2.py3-none-any.whl (997 kB)\n",
            "\u001b[K     |████████████████████████████████| 997 kB 49.5 MB/s \n",
            "\u001b[?25hCollecting openml\n",
            "  Downloading openml-0.12.1.tar.gz (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 58.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.0.16b20201214->autogluon==0.0.16b20201214) (2.3.1)\n",
            "Collecting Pillow<=6.2.1\n",
            "  Downloading Pillow-6.2.1-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 45.1 MB/s \n",
            "\u001b[?25hCollecting lightgbm<4.0,>=3.0\n",
            "  Downloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 65.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx<3.0,>=2.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular==0.0.16b20201214->autogluon==0.0.16b20201214) (2.5.1)\n",
            "Requirement already satisfied: psutil<=5.7.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular==0.0.16b20201214->autogluon==0.0.16b20201214) (5.4.8)\n",
            "Collecting xgboost<1.3,>=1.2\n",
            "  Downloading xgboost-1.2.1-py3-none-manylinux2010_x86_64.whl (148.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 148.9 MB 76 kB/s \n",
            "\u001b[?25hCollecting catboost<0.25,>=0.23.0\n",
            "  Downloading catboost-0.24.4-cp37-none-manylinux1_x86_64.whl (65.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 65.7 MB 12 kB/s \n",
            "\u001b[?25hCollecting autogluon-contrib-nlp\n",
            "  Downloading autogluon_contrib_nlp-0.0.1b20210201-py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 60.1 MB/s \n",
            "\u001b[?25hCollecting pyarrow<=1.0.0\n",
            "  Downloading pyarrow-1.0.0-cp37-cp37m-manylinux2014_x86_64.whl (17.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.2 MB 161 kB/s \n",
            "\u001b[?25hCollecting d8<1.0,>=0.0.2\n",
            "  Downloading d8-0.0.2.post0-py3-none-any.whl (28 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tensorboardx\n",
            "  Downloading tensorboardX-2.2-py2.py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 64.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from gluoncv==0.9.0->autogluon.extra==0.0.16b20201214->autogluon==0.0.16b20201214) (3.13)\n",
            "Collecting autocfg\n",
            "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting decord\n",
            "  Downloading decord-0.5.2-py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1 MB 25.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv==0.9.0->autogluon.extra==0.0.16b20201214->autogluon==0.0.16b20201214) (4.1.2.30)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (0.16.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost<0.25,>=0.23.0->autogluon.tabular==0.0.16b20201214->autogluon==0.0.16b20201214) (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost<0.25,>=0.23.0->autogluon.tabular==0.0.16b20201214->autogluon==0.0.16b20201214) (1.15.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<=0.4.16->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (2.4.7)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 55.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from d8<1.0,>=0.0.2->autogluon.vision==0.0.16b20201214->autogluon==0.0.16b20201214) (1.5.12)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (2.0.0)\n",
            "Collecting dask>=2.6.0\n",
            "  Downloading dask-2021.4.1-py3-none-any.whl (952 kB)\n",
            "\u001b[K     |████████████████████████████████| 952 kB 48.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (56.1.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (7.1.2)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.7.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (0.11.1)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (2.3.0)\n",
            "Collecting cloudpickle>=1.5.0\n",
            "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.0.2)\n",
            "Collecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2021.4.0-py3-none-any.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 59.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm<4.0,>=3.0->autogluon.tabular==0.0.16b20201214->autogluon==0.0.16b20201214) (0.36.2)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx<3.0,>=2.3->autogluon.tabular==0.0.16b20201214->autogluon==0.0.16b20201214) (4.4.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (2.8.1)\n",
            "Collecting cryptography>=2.5\n",
            "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 47.5 MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB)\n",
            "\u001b[K     |████████████████████████████████| 961 kB 34.4 MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (2.20)\n",
            "Collecting locket\n",
            "  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24,>=0.22.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.0.1)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.0.1)\n",
            "Collecting sacremoses>=0.0.38\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 37.0 MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 44.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp->autogluon.text==0.0.16b20201214->autogluon==0.0.16b20201214) (2019.12.20)\n",
            "Collecting flake8\n",
            "  Downloading flake8-3.9.1-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 46.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp->autogluon.text==0.0.16b20201214->autogluon==0.0.16b20201214) (3.12.4)\n",
            "Collecting contextvars\n",
            "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting bokeh\n",
            "  Downloading bokeh-2.3.2rc1.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 56.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->autogluon.extra==0.0.16b20201214->autogluon==0.0.16b20201214) (2.11.3)\n",
            "  Downloading bokeh-2.3.1rc2.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 26.9 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.1rc1.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 41.1 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.1.dev1.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 43.3 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 1.6 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0rc4.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 63 kB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0rc3.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 51.4 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0rc2.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 21 kB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev14.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 24.5 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev13.tar.gz (10.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5 MB 369 bytes/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev12.tar.gz (10.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5 MB 35.6 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev11.tar.gz (10.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5 MB 193 kB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev10.tar.gz (10.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5 MB 20.2 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev9.tar.gz (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 62 kB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev8.tar.gz (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 45.2 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev7.tar.gz (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 173 kB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev5.tar.gz (9.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.3 MB 53.5 MB/s \n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /packages/80/74/8c40c20774600900fc8d1b1527aac1cae35b6167aa0a33f823fd29ae4eba/bokeh-2.3.0.dev3.tar.gz\u001b[0m\n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev3.tar.gz (9.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.3 MB 35 kB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev2.tar.gz (9.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.3 MB 58.8 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev1.tar.gz (9.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.3 MB 39.8 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.3.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 20.6 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.2.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 40.6 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.1.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 55.1 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.0.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 56.9 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.0rc3.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 45.6 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.0rc2.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 45.9 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.0rc1.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 52.1 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.0.dev8.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 56.4 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.0.dev7.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 57.3 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.0.dev6.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 129 kB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.0.dev4.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 38.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->autogluon.extra==0.0.16b20201214->autogluon==0.0.16b20201214) (20.9)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->autogluon.extra==0.0.16b20201214->autogluon==0.0.16b20201214) (3.7.4.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->autogluon.extra==0.0.16b20201214->autogluon==0.0.16b20201214) (1.1.1)\n",
            "Collecting s3transfer<0.5.0,>=0.4.0\n",
            "  Downloading s3transfer-0.4.2-py2.py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting botocore<1.21.0,>=1.20.68\n",
            "  Downloading botocore-1.20.68-py2.py3-none-any.whl (7.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5 MB 40.9 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
            "\u001b[K     |████████████████████████████████| 153 kB 54.7 MB/s \n",
            "\u001b[?25hCollecting immutables>=0.9\n",
            "  Downloading immutables-0.15-cp37-cp37m-manylinux1_x86_64.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting pyflakes<2.4.0,>=2.3.0\n",
            "  Downloading pyflakes-2.3.1-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting pycodestyle<2.8.0,>=2.7.0\n",
            "  Downloading pycodestyle-2.7.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 398 kB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from flake8->autogluon-contrib-nlp->autogluon.text==0.0.16b20201214->autogluon==0.0.16b20201214) (3.10.1)\n",
            "Collecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->flake8->autogluon-contrib-nlp->autogluon.text==0.0.16b20201214->autogluon==0.0.16b20201214) (3.4.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.0.16b20201214->autogluon==0.0.16b20201214) (2020.12.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.0.16b20201214->autogluon==0.0.16b20201214) (4.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (0.10.0)\n",
            "Collecting liac-arff>=2.4.0\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Collecting minio\n",
            "  Downloading minio-7.0.3-py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost<0.25,>=0.23.0->autogluon.tabular==0.0.16b20201214->autogluon==0.0.16b20201214) (1.3.3)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon==0.0.16b20201214) (8.7.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon==0.0.16b20201214) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon==0.0.16b20201214) (20.3.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon==0.0.16b20201214) (1.10.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon==0.0.16b20201214) (1.4.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.0.16b20201214->autogluon==0.0.16b20201214) (1.3)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 52.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (2.10)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-20.4.0-py2.py3-none-any.whl (17 kB)\n",
            "Building wheels for collected packages: ConfigSpace, bokeh, contextvars, openml, liac-arff\n",
            "  Building wheel for ConfigSpace (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.16-cp37-cp37m-linux_x86_64.whl size=2866369 sha256=a875564e8260797fc04f6e7f0e8d3b713f3fdb96be2201a4154404d1b6c07136\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/d8/3f/9d2d97b19d7ee91c9ec915c8432cd0ec1d85d54cb02e33847c\n",
            "  Building wheel for bokeh (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bokeh: filename=bokeh-2.2.0.dev4-py3-none-any.whl size=9259741 sha256=a3733ade683acc9a20b47bf439b31368102a24638b1438e66f7675e9665fe04c\n",
            "  Stored in directory: /root/.cache/pip/wheels/da/38/11/cd7736e6c7a978720593bf4c21438514eb2221f613954e6aa8\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7665 sha256=4e385ac1f28ae1996b182fca9c0306e48d35f2327f16b8e3360f0d98e7e2555a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/11/79/e70e668095c0bb1f94718af672ef2d35ee7a023fee56ef54d9\n",
            "  Building wheel for openml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openml: filename=openml-0.12.1-py3-none-any.whl size=132143 sha256=486a425bdcb8d1b9627edb9d8e6158edfb827ec8ee8c207d5723bc9a4980a840\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/77/16/c4f01efd89dd4a30524ec3bb91ba344b2c890031c0a85653b2\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11731 sha256=7a17964af8a1f1ae255832c1d272c5afde22060b9f39a57d974b1c0ae57c65cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/0f/15/332ca86cbebf25ddf98518caaf887945fbe1712b97a0f2493b\n",
            "Successfully built ConfigSpace bokeh contextvars openml liac-arff\n",
            "Installing collected packages: urllib3, locket, jmespath, partd, fsspec, cloudpickle, botocore, s3transfer, pynacl, pyaml, dask, cryptography, bcrypt, xmltodict, scikit-optimize, pyflakes, pycodestyle, pyarrow, portalocker, paramiko, minio, mccabe, liac-arff, immutables, distributed, ConfigSpace, boto3, yacs, xxhash, tokenizers, tensorboardx, sentencepiece, sacremoses, sacrebleu, Pillow, openml, flake8, decord, contextvars, autogluon.core, autocfg, xgboost, lightgbm, gluoncv, d8, catboost, bokeh, autogluon.mxnet, autogluon-contrib-nlp, autogluon.vision, autogluon.text, autogluon.tabular, autogluon.extra, autogluon\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2.12.0\n",
            "    Uninstalling dask-2.12.0:\n",
            "      Successfully uninstalled dask-2.12.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 3.0.0\n",
            "    Uninstalling pyarrow-3.0.0:\n",
            "      Successfully uninstalled pyarrow-3.0.0\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Attempting uninstall: bokeh\n",
            "    Found existing installation: bokeh 2.3.1\n",
            "    Uninstalling bokeh-2.3.1:\n",
            "      Successfully uninstalled bokeh-2.3.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "panel 0.11.2 requires bokeh<2.4.0,>=2.3.0, but you have bokeh 2.2.0.dev4 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed ConfigSpace-0.4.16 Pillow-6.2.1 autocfg-0.0.8 autogluon-0.0.16b20201214 autogluon-contrib-nlp-0.0.1b20210201 autogluon.core-0.0.16b20201214 autogluon.extra-0.0.16b20201214 autogluon.mxnet-0.0.16b20201214 autogluon.tabular-0.0.16b20201214 autogluon.text-0.0.16b20201214 autogluon.vision-0.0.16b20201214 bcrypt-3.2.0 bokeh-2.2.0.dev4 boto3-1.17.68 botocore-1.20.68 catboost-0.24.4 cloudpickle-1.6.0 contextvars-2.4 cryptography-3.4.7 d8-0.0.2.post0 dask-2021.4.1 decord-0.5.2 distributed-2021.4.1 flake8-3.9.1 fsspec-2021.4.0 gluoncv-0.9.0 immutables-0.15 jmespath-0.10.0 liac-arff-2.5.0 lightgbm-3.2.1 locket-0.2.1 mccabe-0.6.1 minio-7.0.3 openml-0.12.1 paramiko-2.7.2 partd-1.2.0 portalocker-2.0.0 pyaml-20.4.0 pyarrow-1.0.0 pycodestyle-2.7.0 pyflakes-2.3.1 pynacl-1.4.0 s3transfer-0.4.2 sacrebleu-1.5.1 sacremoses-0.0.45 scikit-optimize-0.8.1 sentencepiece-0.1.95 tensorboardx-2.2 tokenizers-0.9.4 urllib3-1.25.11 xgboost-1.2.1 xmltodict-0.12.0 xxhash-2.0.2 yacs-0.1.8\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "contextvars",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (4.10.1)\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-5.5.4-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.3.5)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.5.0)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.1.1)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.0.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (56.1.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (4.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0->ipykernel) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0->ipykernel) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.1.0->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel) (2.8.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel) (22.0.3)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel) (4.7.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=5.0.0->ipykernel) (0.7.0)\n",
            "Installing collected packages: ipykernel\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 5.5.4 which is incompatible.\u001b[0m\n",
            "Successfully installed ipykernel-5.5.4\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipykernel"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYjOiA4F611f"
      },
      "source": [
        "import autogluon as ag\n",
        "from autogluon.tabular import TabularPrediction as task\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import gc\n",
        "import math\n",
        "import os\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orx5fiPv619J",
        "outputId": "4022716a-1e01-431d-c95a-74103dad236c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/NASA PM_estimation/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMqD4lM86c6P"
      },
      "source": [
        "small_grid = pd.read_csv(\"Data/datasets/Small_Grid.csv\")\n",
        "df = pd.read_csv(\"Data/datasets/Train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wLDoYbT62E7"
      },
      "source": [
        "# Make a dataset with the average PM by day\n",
        "PM = df[[\"Day\", \"PM\"]].groupby('Day').mean().reset_index()\n",
        "# print(PM.head())\n",
        "\n",
        "medianPM_day = np.array(PM[PM['PM']==np.median(PM['PM'])]['Day'])\n",
        "maxPM_day = np.array(PM[PM['PM']==np.amax(PM['PM'])]['Day'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJUiXD0I6kg4"
      },
      "source": [
        "def fitgrid(hyperparameters):\n",
        "  features = ['Day', 'Elevation', 'Emissions', 'Forest',\n",
        "      'Roads', 'Streets', 'Plumes_High', 'Plumes_Med', 'Plumes_Low',\n",
        "      'Max_Temp', 'Max_Wind', 'Precip', 'Rel_Humidity', 'Wind_Dir', 'BLH',\n",
        "      'AOD', 'PM']\n",
        "  label_column = 'PM'\n",
        "\n",
        "  train_data = task.Dataset(df[features])\n",
        "  test_data = task.Dataset(small_grid[features])\n",
        "\n",
        "  predictor = task.fit(train_data=train_data, \n",
        "                        label=label_column, \n",
        "                        hyperparameters=hyperparameters, \n",
        "                        # time_limits = 60*3,\n",
        "                        # hyperparameter_tune=True, \n",
        "                        eval_metric='r2')\n",
        "\n",
        "  test_data_nolab = test_data.drop(labels = [label_column], axis = 1)\n",
        "  # y_pred = predictor.predict(test_data_nolab)\n",
        "  test_data['y_pred'] = predictor.predict(test_data_nolab)\n",
        "  print(test_data.head())\n",
        "  test_data['Id'] = small_grid['Id']\n",
        "  test_data['Day'] = test_data['Day'].apply(lambda x: 'Day'+str(x))\n",
        "  test_data = test_data.pivot(index='Id', columns='Day', values='y_pred')\n",
        "\n",
        "  return test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8rrG17qfbyO",
        "outputId": "a80aee9c-6fb5-4a6c-d89c-3921b527f3d4"
      },
      "source": [
        "CAT = fitgrid({'CAT': {}})\n",
        "CAT.to_csv(\"Data/output/grids/CAT.csv\", index = True)\n",
        "CAT.mean(axis = 1).to_csv(\"Data/output/grids/avg/CAT_Avg.csv\", index = True)\n",
        "CAT[['Day'+str(maxPM_day[0])]].mean(axis = 1).to_csv(\"Data/output/grids/high/CAT_high.csv\", index = True)\n",
        "CAT[['Day'+str(medianPM_day[0])]].mean(axis = 1).to_csv(\"Data/output/grids/low/CAT_low.csv\", index = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210507_151200/\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to AutogluonModels/ag-20210507_151200/\n",
            "AutoGluon Version:  0.0.16b20201214\n",
            "Train Data Rows:    9900\n",
            "Train Data Columns: 16\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.81719, 7.72732)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11800.06 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 11 | ['Elevation', 'Emissions', 'Roads', 'Streets', 'Max_Temp', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 11 | ['Elevation', 'Emissions', 'Roads', 'Streets', 'Max_Temp', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t16 features in original data used to generate 16 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.15s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'r2'\n",
            "Fitting model: CatBoost ...\n",
            "\t0.8062\t = Validation r2 score\n",
            "\t11.15s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L1 ...\n",
            "\t0.8062\t = Validation r2 score\n",
            "\t0.0s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 11.56s ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   Day  Elevation  Emissions  Forest  ...         BLH  AOD  PM     y_pred\n",
            "0    1        0.0        0.0       0  ...  978.736816  NaN NaN   9.099906\n",
            "1   10        0.0        0.0       0  ...  432.832642  NaN NaN   4.846766\n",
            "2  100        0.0        0.0       0  ...   45.136700  NaN NaN   7.670850\n",
            "3  101        0.0        0.0       0  ...  147.480194  NaN NaN  10.681348\n",
            "4  102        0.0        0.0       0  ...  248.710907  NaN NaN   5.391977\n",
            "\n",
            "[5 rows x 18 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c9JTG0AgDw1",
        "outputId": "323b5a8e-0f1a-4de0-abf1-eeca01b042d2"
      },
      "source": [
        "NN = fitgrid({'NN': {}})\n",
        "NN.to_csv(\"Data/output/grids/NN.csv\", index = True)\n",
        "NN.mean(axis = 1).to_csv(\"Data/output/grids/avg/NN_Avg.csv\", index = True)\n",
        "NN[['Day'+str(maxPM_day[0])]].mean(axis = 1).to_csv(\"Data/output/grids/high/NN_high.csv\", index = True)\n",
        "NN[['Day'+str(medianPM_day[0])]].mean(axis = 1).to_csv(\"Data/output/grids/low/NN_low.csv\", index = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210507_154654/\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to AutogluonModels/ag-20210507_154654/\n",
            "AutoGluon Version:  0.0.16b20201214\n",
            "Train Data Rows:    9900\n",
            "Train Data Columns: 16\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.81719, 7.72732)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11576.96 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 11 | ['Elevation', 'Emissions', 'Roads', 'Streets', 'Max_Temp', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 11 | ['Elevation', 'Emissions', 'Roads', 'Streets', 'Max_Temp', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t16 features in original data used to generate 16 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.16s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'r2'\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\t0.5796\t = Validation r2 score\n",
            "\t81.14s\t = Training runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L1 ...\n",
            "\t0.5796\t = Validation r2 score\n",
            "\t0.0s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 81.85s ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   Day  Elevation  Emissions  Forest  ...         BLH  AOD  PM     y_pred\n",
            "0    1        0.0        0.0       0  ...  978.736816  NaN NaN   8.955448\n",
            "1   10        0.0        0.0       0  ...  432.832642  NaN NaN  12.338755\n",
            "2  100        0.0        0.0       0  ...   45.136700  NaN NaN  10.635022\n",
            "3  101        0.0        0.0       0  ...  147.480194  NaN NaN  18.607294\n",
            "4  102        0.0        0.0       0  ...  248.710907  NaN NaN  14.622022\n",
            "\n",
            "[5 rows x 18 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjTKFpY7JesM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e0ba19-0692-434f-e0cb-b39a5e40cbc4"
      },
      "source": [
        "GBM = fitgrid({'GBM': {}})\n",
        "GBM.to_csv(\"Data/output/grids/GMB.csv\", index = True)\n",
        "GBM.mean(axis = 1).to_csv(\"Data/output/grids/avg/GMB_Avg.csv\", index = True)\n",
        "GBM[['Day'+str(maxPM_day[0])]].mean(axis = 1).to_csv(\"Data/output/grids/high/GMB_high.csv\", index = True)\n",
        "GBM[['Day'+str(medianPM_day[0])]].mean(axis = 1).to_csv(\"Data/output/grids/low/GMB_low.csv\", index = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210507_155100/\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to AutogluonModels/ag-20210507_155100/\n",
            "AutoGluon Version:  0.0.16b20201214\n",
            "Train Data Rows:    9900\n",
            "Train Data Columns: 16\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.81719, 7.72732)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11546.24 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 11 | ['Elevation', 'Emissions', 'Roads', 'Streets', 'Max_Temp', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 11 | ['Elevation', 'Emissions', 'Roads', 'Streets', 'Max_Temp', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t16 features in original data used to generate 16 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.14s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'r2'\n",
            "Fitting model: LightGBM ...\n",
            "/usr/local/lib/python3.7/dist-packages/fsspec/__init__.py:47: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for spec in entry_points.get(\"fsspec.specs\", []):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1000]\ttrain_set's l2: 0.757154\ttrain_set's r2: 0.986108\tvalid_set's l2: 8.87936\tvalid_set's r2: 0.813689\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\t0.8153\t = Validation r2 score\n",
            "\t5.49s\t = Training runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L1 ...\n",
            "\t0.8153\t = Validation r2 score\n",
            "\t0.0s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 6.35s ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   Day  Elevation  Emissions  Forest  ...         BLH  AOD  PM     y_pred\n",
            "0    1        0.0        0.0       0  ...  978.736816  NaN NaN   8.286654\n",
            "1   10        0.0        0.0       0  ...  432.832642  NaN NaN   3.303148\n",
            "2  100        0.0        0.0       0  ...   45.136700  NaN NaN   8.712801\n",
            "3  101        0.0        0.0       0  ...  147.480194  NaN NaN  11.388944\n",
            "4  102        0.0        0.0       0  ...  248.710907  NaN NaN   4.925733\n",
            "\n",
            "[5 rows x 18 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_LwMYVnWFnk",
        "outputId": "606e2aaa-8066-4cf3-cb3c-6b1c2d26d8c9"
      },
      "source": [
        "RF = fitgrid({'RF': {}})\n",
        "RF.to_csv(\"Data/output/grids/RF.csv\", index = True)\n",
        "RF.mean(axis = 1).to_csv(\"Data/output/grids/avg/RF_Avg.csv\", index = True)\n",
        "RF[['Day'+str(maxPM_day[0])]].mean(axis = 1).to_csv(\"Data/output/grids/high/RF_high.csv\", index = True)\n",
        "RF[['Day'+str(medianPM_day[0])]].mean(axis = 1).to_csv(\"Data/output/grids/low/RF_low.csv\", index = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210507_182238/\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to AutogluonModels/ag-20210507_182238/\n",
            "AutoGluon Version:  0.0.16b20201214\n",
            "Train Data Rows:    9900\n",
            "Train Data Columns: 16\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.81719, 7.72732)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11814.51 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 11 | ['Elevation', 'Emissions', 'Roads', 'Streets', 'Max_Temp', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 11 | ['Elevation', 'Emissions', 'Roads', 'Streets', 'Max_Temp', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t16 features in original data used to generate 16 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.17s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'r2'\n",
            "Fitting model: RandomForest ...\n",
            "\t0.6839\t = Validation r2 score\n",
            "\t15.61s\t = Training runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L1 ...\n",
            "\t0.6839\t = Validation r2 score\n",
            "\t0.0s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 18.31s ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   Day  Elevation  Emissions  Forest  ...         BLH  AOD  PM     y_pred\n",
            "0    1        0.0        0.0       0  ...  978.736816  NaN NaN  10.218667\n",
            "1   10        0.0        0.0       0  ...  432.832642  NaN NaN   4.897666\n",
            "2  100        0.0        0.0       0  ...   45.136700  NaN NaN  10.132334\n",
            "3  101        0.0        0.0       0  ...  147.480194  NaN NaN  10.465777\n",
            "4  102        0.0        0.0       0  ...  248.710907  NaN NaN   6.422389\n",
            "\n",
            "[5 rows x 18 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8LJzLxZWSCv",
        "outputId": "e1b28267-965a-4726-e41c-7acd802eaecc"
      },
      "source": [
        "XT = fitgrid({'XT': {}})\n",
        "XT.to_csv(\"Data/output/grids/XT.csv\", index = True)\n",
        "XT.mean(axis = 1).to_csv(\"Data/output/grids/avg/XT_Avg.csv\", index = True)\n",
        "XT[['Day'+str(maxPM_day[0])]].mean(axis = 1).to_csv(\"Data/output/grids/high/XT_high.csv\", index = True)\n",
        "XT[['Day'+str(medianPM_day[0])]].mean(axis = 1).to_csv(\"Data/output/grids/low/XT_low.csv\", index = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210507_182600/\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to AutogluonModels/ag-20210507_182600/\n",
            "AutoGluon Version:  0.0.16b20201214\n",
            "Train Data Rows:    9900\n",
            "Train Data Columns: 16\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.81719, 7.72732)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11811.17 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 11 | ['Elevation', 'Emissions', 'Roads', 'Streets', 'Max_Temp', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 11 | ['Elevation', 'Emissions', 'Roads', 'Streets', 'Max_Temp', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t16 features in original data used to generate 16 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.16s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'r2'\n",
            "Fitting model: ExtraTrees ...\n",
            "\t0.7669\t = Validation r2 score\n",
            "\t7.06s\t = Training runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L1 ...\n",
            "\t0.7669\t = Validation r2 score\n",
            "\t0.0s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 10.85s ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   Day  Elevation  Emissions  Forest  ...         BLH  AOD  PM    y_pred\n",
            "0    1        0.0        0.0       0  ...  978.736816  NaN NaN  6.907166\n",
            "1   10        0.0        0.0       0  ...  432.832642  NaN NaN  5.191667\n",
            "2  100        0.0        0.0       0  ...   45.136700  NaN NaN  9.248000\n",
            "3  101        0.0        0.0       0  ...  147.480194  NaN NaN  9.151000\n",
            "4  102        0.0        0.0       0  ...  248.710907  NaN NaN  6.492833\n",
            "\n",
            "[5 rows x 18 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTybn75kWaDw",
        "outputId": "277d1b68-2324-478f-b1c7-545230ede895"
      },
      "source": [
        "KNN = fitgrid({'KNN': {}})\n",
        "KNN.to_csv(\"Data/output/grids/KNN.csv\", index = True)\n",
        "KNN.mean(axis = 1).to_csv(\"Data/output/grids/avg/KNN_Avg.csv\", index = True)\n",
        "KNN[['Day'+str(maxPM_day[0])]].mean(axis = 1).to_csv(\"Data/output/grids/high/KNN_high.csv\", index = True)\n",
        "KNN[['Day'+str(medianPM_day[0])]].mean(axis = 1).to_csv(\"Data/output/grids/low/KNN_low.csv\", index = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210507_182834/\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to AutogluonModels/ag-20210507_182834/\n",
            "AutoGluon Version:  0.0.16b20201214\n",
            "Train Data Rows:    9900\n",
            "Train Data Columns: 16\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.81719, 7.72732)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11796.93 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 11 | ['Elevation', 'Emissions', 'Roads', 'Streets', 'Max_Temp', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 11 | ['Elevation', 'Emissions', 'Roads', 'Streets', 'Max_Temp', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t16 features in original data used to generate 16 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.17s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'r2'\n",
            "Fitting model: KNeighbors ...\n",
            "\t0.0899\t = Validation r2 score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L1 ...\n",
            "\t0.0899\t = Validation r2 score\n",
            "\t0.0s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 0.64s ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   Day  Elevation  Emissions  Forest  ...         BLH  AOD  PM  y_pred\n",
            "0    1        0.0        0.0       0  ...  978.736816  NaN NaN    7.03\n",
            "1   10        0.0        0.0       0  ...  432.832642  NaN NaN    8.48\n",
            "2  100        0.0        0.0       0  ...   45.136700  NaN NaN   11.90\n",
            "3  101        0.0        0.0       0  ...  147.480194  NaN NaN    8.70\n",
            "4  102        0.0        0.0       0  ...  248.710907  NaN NaN    6.47\n",
            "\n",
            "[5 rows x 18 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwZmOBHBACkM",
        "outputId": "4520030b-eeda-4dbc-ff23-9b691adc3acc"
      },
      "source": [
        "Default = fitgrid('default')\n",
        "Default.to_csv(\"Data/output/grids/Default.csv\", index = True)\n",
        "Default.mean(axis = 1).to_csv(\"Data/output/grids/avg/Default_Avg.csv\", index = True)\n",
        "Default[['Day'+str(maxPM_day[0])]].mean(axis = 1).to_csv(\"Data/output/grids/high/Default_high.csv\", index = True)\n",
        "Default[['Day'+str(medianPM_day[0])]].mean(axis = 1).to_csv(\"Data/output/grids/low/Default_low.csv\", index = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210507_183033/\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to AutogluonModels/ag-20210507_183033/\n",
            "AutoGluon Version:  0.0.16b20201214\n",
            "Train Data Rows:    9900\n",
            "Train Data Columns: 16\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.81719, 7.72732)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11787.01 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 11 | ['Elevation', 'Emissions', 'Roads', 'Streets', 'Max_Temp', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 11 | ['Elevation', 'Emissions', 'Roads', 'Streets', 'Max_Temp', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t16 features in original data used to generate 16 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.16s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'r2'\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t0.6839\t = Validation r2 score\n",
            "\t15.59s\t = Training runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t0.7669\t = Validation r2 score\n",
            "\t7.36s\t = Training runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.0899\t = Validation r2 score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.1142\t = Validation r2 score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "/usr/local/lib/python3.7/dist-packages/fsspec/__init__.py:47: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for spec in entry_points.get(\"fsspec.specs\", []):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1000]\ttrain_set's l2: 0.757154\ttrain_set's r2: 0.986108\tvalid_set's l2: 8.87936\tvalid_set's r2: 0.813689\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\t0.8153\t = Validation r2 score\n",
            "\t5.37s\t = Training runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1000]\ttrain_set's l2: 3.68413\ttrain_set's r2: 0.938201\tvalid_set's l2: 10.0657\tvalid_set's r2: 0.789473\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\t0.7921\t = Validation r2 score\n",
            "\t5.45s\t = Training runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.8062\t = Validation r2 score\n",
            "\t11.31s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.8571\t = Validation r2 score\n",
            "\t16.36s\t = Training runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\t0.6128\t = Validation r2 score\n",
            "\t65.08s\t = Training runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: LightGBMCustom ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1000]\ttrain_set's l2: 0.150177\ttrain_set's r2: 0.996147\tvalid_set's l2: 12.1705\tvalid_set's r2: 0.74503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\t0.7487\t = Validation r2 score\n",
            "\t13.45s\t = Training runtime\n",
            "\t0.19s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L1 ...\n",
            "\t0.8581\t = Validation r2 score\n",
            "\t0.53s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 150.78s ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   Day  Elevation  Emissions  Forest  ...         BLH  AOD  PM     y_pred\n",
            "0    1        0.0        0.0       0  ...  978.736816  NaN NaN   8.329772\n",
            "1   10        0.0        0.0       0  ...  432.832642  NaN NaN   3.859710\n",
            "2  100        0.0        0.0       0  ...   45.136700  NaN NaN   8.874905\n",
            "3  101        0.0        0.0       0  ...  147.480194  NaN NaN  12.082391\n",
            "4  102        0.0        0.0       0  ...  248.710907  NaN NaN   6.324549\n",
            "\n",
            "[5 rows x 18 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ysUpP0aYtKg"
      },
      "source": [
        "TwoStage = pd.read_csv(\"Data/output/grids/2S_Full_Grid.csv\", index_col = 0)\n",
        "TwoStage.mean(axis = 1).to_csv(\"Data/output/grids/avg/TwoStage_Avg.csv\", index = True)\n",
        "TwoStage[['Day'+str(maxPM_day[0])]].mean(axis = 1).to_csv(\"Data/output/grids/high/TwoStage_high.csv\", index = True)\n",
        "TwoStage[['Day'+str(medianPM_day[0])]].mean(axis = 1).to_csv(\"Data/output/grids/low/TwoStage_low.csv\", index = True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}