{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_model_random_CV2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anna-boser/AutoGluon_PM_paper/blob/main/ML_model_random_CV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84oP5noMJ1Yj"
      },
      "source": [
        "# Set up Autogluon and get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hunLgsNTea_e",
        "outputId": "ef9b069c-6e3d-4e29-b47d-d9d4faa6871f"
      },
      "source": [
        "# Uninstall mkl for faster neural-network training time\n",
        "!pip uninstall -y mkl\n",
        "# Upgrade pip to ensure the latest package versions are available\n",
        "!pip install -U pip\n",
        "# Upgrade setuptools to be compatible with namespace packages\n",
        "!pip install -U setuptools wheel\n",
        "!pip install -U \"mxnet<2.0.0\"\n",
        "# Install autogluon (Tutorial based on autogluon==0.1.0)\n",
        "!pip install autogluon\n",
        "# Upgrade ipykernel (Necessary for Colab)\n",
        "!pip install -U ipykernel"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: mkl 2019.0\n",
            "Uninstalling mkl-2019.0:\n",
            "  Successfully uninstalled mkl-2019.0\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.0.4-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.0.4\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-62.1.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n",
            "Installing collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-62.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting mxnet<2.0.0\n",
            "  Downloading mxnet-1.9.0-py3-none-manylinux2014_x86_64.whl (47.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<2.0.0) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<2.0.0) (1.21.6)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (3.0.4)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.9.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting autogluon\n",
            "  Downloading autogluon-0.4.0-py3-none-any.whl (9.5 kB)\n",
            "Collecting autogluon.text==0.4.0\n",
            "  Downloading autogluon.text-0.4.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.core[all]==0.4.0\n",
            "  Downloading autogluon.core-0.4.0-py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.2/188.2 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.features==0.4.0\n",
            "  Downloading autogluon.features-0.4.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.vision==0.4.0\n",
            "  Downloading autogluon.vision-0.4.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.6/48.6 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.tabular[all]==0.4.0\n",
            "  Downloading autogluon.tabular-0.4.0-py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.0/267.0 KB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dask<=2021.11.2,>=2021.09.1\n",
            "  Downloading dask-2021.11.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distributed<=2021.11.2,>=2021.09.1\n",
            "  Downloading distributed-2021.11.2-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 KB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<1.4,>=1.2.5 in /usr/local/lib/python3.7/dist-packages (from autogluon.core[all]==0.4.0->autogluon) (1.3.5)\n",
            "Collecting scipy<1.8.0,>=1.5.4\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<1.1,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core[all]==0.4.0->autogluon) (1.0.2)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.21.46-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.5/132.5 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core[all]==0.4.0->autogluon) (4.64.0)\n",
            "Requirement already satisfied: numpy<1.23,>=1.21 in /usr/local/lib/python3.7/dist-packages (from autogluon.core[all]==0.4.0->autogluon) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from autogluon.core[all]==0.4.0->autogluon) (3.2.2)\n",
            "Collecting autogluon.common==0.4.0\n",
            "  Downloading autogluon.common-0.4.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autogluon.core[all]==0.4.0->autogluon) (2.23.0)\n",
            "Collecting ray<1.9,>=1.7\n",
            "  Downloading ray-1.8.0-cp37-cp37m-manylinux2014_x86_64.whl (54.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil<5.9,>=5.7.3\n",
            "  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.3/296.3 KB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx<3.0,>=2.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.4.0->autogluon) (2.6.3)\n",
            "Collecting fastai<2.6,>=2.3.1\n",
            "  Downloading fastai-2.5.6-py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.3/188.3 KB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<1.11,>=1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.4.0->autogluon) (1.10.0+cu111)\n",
            "Collecting xgboost<1.5,>=1.4\n",
            "  Downloading xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.7/166.7 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting catboost<1.1,>=1.0\n",
            "  Downloading catboost-1.0.5-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightgbm<3.4,>=3.3\n",
            "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-image<0.20.0,>=0.19.1\n",
            "  Downloading scikit_image-0.19.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open<5.3.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.text==0.4.0->autogluon) (5.2.1)\n",
            "Collecting pytorch-lightning<1.6.0,>=1.5.10\n",
            "  Downloading pytorch_lightning-1.5.10-py3-none-any.whl (527 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.7/527.7 KB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon-contrib-nlp==0.0.1b20220208\n",
            "  Downloading autogluon_contrib_nlp-0.0.1b20220208-py3-none-any.whl (157 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 KB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers<4.17.0,>=4.16.2\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece<0.2.0,>=0.1.95\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.2.0,>=2.1.1\n",
            "  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm<0.6.0,>=0.5.4\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.5/431.5 KB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairscale<0.5.0,>=0.4.5\n",
            "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.2/248.2 KB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Pillow<9.1.0,>=9.0.0\n",
            "  Downloading Pillow-9.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics<0.8.0,>=0.7.2\n",
            "  Downloading torchmetrics-0.7.3-py3-none-any.whl (398 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m398.2/398.2 KB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nptyping<1.5.0,>=1.4.4\n",
            "  Downloading nptyping-1.4.4-py3-none-any.whl (31 kB)\n",
            "Collecting gluoncv<0.10.6,>=0.10.5\n",
            "  Downloading gluoncv-0.10.5-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers>=0.9.4\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contextvars\n",
            "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flake8\n",
            "  Downloading flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.4.0->autogluon) (3.17.3)\n",
            "Collecting sacremoses>=0.0.38\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m895.2/895.2 KB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.4.0->autogluon) (6.0.1)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.4.0->autogluon) (2019.12.20)\n",
            "Collecting sentencepiece<0.2.0,>=0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.4.0->autogluon) (5.5.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.4.0->autogluon) (0.8.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.4.0->autogluon) (1.15.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.4.0->autogluon) (21.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.4.0->autogluon) (3.13)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.4.0->autogluon) (0.11.2)\n",
            "Collecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.4.0->autogluon) (1.3.0)\n",
            "Collecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.1/136.1 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.4.0->autogluon) (1.7.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.4.0->autogluon) (2.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.4.0->autogluon) (62.1.0)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.4.0->autogluon) (5.1.1)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.4.0->autogluon) (7.1.2)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.4.0->autogluon) (2.1.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.4.0->autogluon) (2.11.3)\n",
            "Collecting cloudpickle>=1.1.1\n",
            "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.4.0->autogluon) (1.0.3)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai<2.6,>=2.3.1->autogluon.tabular[all]==0.4.0->autogluon) (0.11.1+cu111)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai<2.6,>=2.3.1->autogluon.tabular[all]==0.4.0->autogluon) (1.0.2)\n",
            "Collecting fastdownload<2,>=0.0.5\n",
            "  Downloading fastdownload-0.0.5-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai<2.6,>=2.3.1->autogluon.tabular[all]==0.4.0->autogluon) (2.2.4)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai<2.6,>=2.3.1->autogluon.tabular[all]==0.4.0->autogluon) (22.0.4)\n",
            "Collecting fastcore<1.5,>=1.3.27\n",
            "  Downloading fastcore-1.4.2-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autocfg\n",
            "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.4.0->autogluon) (4.1.2.30)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]==0.4.0->autogluon) (0.37.1)\n",
            "Collecting typish>=1.7.0\n",
            "  Downloading typish-1.9.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 KB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<1.4,>=1.2.5->autogluon.core[all]==0.4.0->autogluon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<1.4,>=1.2.5->autogluon.core[all]==0.4.0->autogluon) (2022.1)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<1.6.0,>=1.5.10->autogluon.text==0.4.0->autogluon) (2.8.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.4/952.4 KB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.2/829.2 KB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<1.6.0,>=1.5.10->autogluon.text==0.4.0->autogluon) (4.1.1)\n",
            "Collecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray<1.9,>=1.7->autogluon.core[all]==0.4.0->autogluon) (4.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray<1.9,>=1.7->autogluon.core[all]==0.4.0->autogluon) (3.6.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray<1.9,>=1.7->autogluon.core[all]==0.4.0->autogluon) (21.4.0)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray<1.9,>=1.7->autogluon.core[all]==0.4.0->autogluon) (1.44.0)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.2.2-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.4/226.4 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.text==0.4.0->autogluon) (2.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.text==0.4.0->autogluon) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.text==0.4.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1,>=1.0.0->autogluon.core[all]==0.4.0->autogluon) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1,>=1.0.0->autogluon.core[all]==0.4.0->autogluon) (3.1.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.17.0,>=4.16.2->autogluon.text==0.4.0->autogluon) (4.11.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting botocore<1.25.0,>=1.24.46\n",
            "  Downloading botocore-1.24.46-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core[all]==0.4.0->autogluon) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core[all]==0.4.0->autogluon) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core[all]==0.4.0->autogluon) (1.4.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core[all]==0.4.0->autogluon) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core[all]==0.4.0->autogluon) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core[all]==0.4.0->autogluon) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core[all]==0.4.0->autogluon) (2.10)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/128.0 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting locket\n",
            "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting async-timeout>=4.0.2\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<4.17.0,>=4.16.2->autogluon.text==0.4.0->autogluon) (3.8.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.6,>=2.3.1->autogluon.tabular[all]==0.4.0->autogluon) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.6,>=2.3.1->autogluon.tabular[all]==0.4.0->autogluon) (3.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.6,>=2.3.1->autogluon.tabular[all]==0.4.0->autogluon) (1.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.6,>=2.3.1->autogluon.tabular[all]==0.4.0->autogluon) (2.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.6,>=2.3.1->autogluon.tabular[all]==0.4.0->autogluon) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.6,>=2.3.1->autogluon.tabular[all]==0.4.0->autogluon) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.6,>=2.3.1->autogluon.tabular[all]==0.4.0->autogluon) (0.9.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.6,>=2.3.1->autogluon.tabular[all]==0.4.0->autogluon) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<2.6,>=2.3.1->autogluon.tabular[all]==0.4.0->autogluon) (0.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.6.0,>=1.5.10->autogluon.text==0.4.0->autogluon) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.6.0,>=1.5.10->autogluon.text==0.4.0->autogluon) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.6.0,>=1.5.10->autogluon.text==0.4.0->autogluon) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.6.0,>=1.5.10->autogluon.text==0.4.0->autogluon) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.6.0,>=1.5.10->autogluon.text==0.4.0->autogluon) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.6.0,>=1.5.10->autogluon.text==0.4.0->autogluon) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.6.0,>=1.5.10->autogluon.text==0.4.0->autogluon) (1.35.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.4.0->autogluon) (1.0.1)\n",
            "Collecting immutables>=0.9\n",
            "  Downloading immutables-0.17-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.5/116.5 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting pyflakes<2.5.0,>=2.4.0\n",
            "  Downloading pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycodestyle<2.9.0,>=2.8.0\n",
            "  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata\n",
            "  Downloading importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.4.0->autogluon) (2.0.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray<1.9,>=1.7->autogluon.core[all]==0.4.0->autogluon) (5.7.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray<1.9,>=1.7->autogluon.core[all]==0.4.0->autogluon) (0.18.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost<1.1,>=1.0->autogluon.tabular[all]==0.4.0->autogluon) (8.0.1)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20220208->autogluon.text==0.4.0->autogluon) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray<1.9,>=1.7->autogluon.core[all]==0.4.0->autogluon) (1.14.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.6.0,>=1.5.10->autogluon.text==0.4.0->autogluon) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.6.0,>=1.5.10->autogluon.text==0.4.0->autogluon) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.6.0,>=1.5.10->autogluon.text==0.4.0->autogluon) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning<1.6.0,>=1.5.10->autogluon.text==0.4.0->autogluon) (1.3.1)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 KB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec>=0.6.0->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.4.0->autogluon) (2.0.12)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.8/271.8 KB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.6.0,>=1.5.10->autogluon.text==0.4.0->autogluon) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning<1.6.0,>=1.5.10->autogluon.text==0.4.0->autogluon) (3.2.0)\n",
            "Building wheels for collected packages: fairscale, antlr4-python3-runtime, future, contextvars\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307243 sha256=de625b42fe157e4bb7d83e4a6b922f2fd0479a5cc9ef9f1cf5970561c0c5d952\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/4f/0b/94c29ea06dfad93260cb0377855f87b7b863312317a7f69fe7\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=accd4636f8bf6f6d98edb0d938e414e50c9936726efbf7195be6059d5bc3a493\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=e81121783ac8ba08a08b342893ede0d3f6707ec7adc5900f9698f77af9901c33\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7681 sha256=5897f8605f805c5768d44ed88039a386e93b4299b24c3be967f12daa1c48648e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/11/79/e70e668095c0bb1f94718af672ef2d35ee7a023fee56ef54d9\n",
            "Successfully built fairscale antlr4-python3-runtime future contextvars\n",
            "Installing collected packages: typish, tokenizers, sentencepiece, mccabe, antlr4-python3-runtime, urllib3, setuptools, scipy, sacremoses, pyyaml, pyflakes, pyDeprecate, pycodestyle, psutil, portalocker, Pillow, nptyping, multidict, locket, jmespath, importlib-metadata, immutables, future, fsspec, frozenlist, deprecated, colorama, cloudpickle, asynctest, async-timeout, yarl, yacs, xgboost, torchmetrics, sacrebleu, redis, partd, omegaconf, markdown, flake8, fastcore, fairscale, contextvars, botocore, autocfg, aiosignal, timm, scikit-image, s3transfer, ray, lightgbm, huggingface-hub, gluoncv, fastdownload, dask, catboost, autogluon-contrib-nlp, aiohttp, transformers, distributed, boto3, fastai, autogluon.common, pytorch-lightning, autogluon.features, autogluon.core, autogluon.vision, autogluon.text, autogluon.tabular, autogluon\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 62.1.0\n",
            "    Uninstalling setuptools-62.1.0:\n",
            "      Successfully uninstalled setuptools-62.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.11.3\n",
            "    Uninstalling importlib-metadata-4.11.3:\n",
            "      Successfully uninstalled importlib-metadata-4.11.3\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.3.6\n",
            "    Uninstalling Markdown-3.3.6:\n",
            "      Successfully uninstalled Markdown-3.3.6\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2.12.0\n",
            "    Uninstalling dask-2.12.0:\n",
            "      Successfully uninstalled dask-2.12.0\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "  Attempting uninstall: fastai\n",
            "    Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.0.1 aiohttp-3.8.1 aiosignal-1.2.0 antlr4-python3-runtime-4.8 async-timeout-4.0.2 asynctest-0.13.0 autocfg-0.0.8 autogluon-0.4.0 autogluon-contrib-nlp-0.0.1b20220208 autogluon.common-0.4.0 autogluon.core-0.4.0 autogluon.features-0.4.0 autogluon.tabular-0.4.0 autogluon.text-0.4.0 autogluon.vision-0.4.0 boto3-1.21.46 botocore-1.24.46 catboost-1.0.5 cloudpickle-2.0.0 colorama-0.4.4 contextvars-2.4 dask-2021.11.2 deprecated-1.2.13 distributed-2021.11.2 fairscale-0.4.6 fastai-2.5.6 fastcore-1.4.2 fastdownload-0.0.5 flake8-4.0.1 frozenlist-1.3.0 fsspec-2022.3.0 future-0.18.2 gluoncv-0.10.5 huggingface-hub-0.5.1 immutables-0.17 importlib-metadata-4.2.0 jmespath-1.0.0 lightgbm-3.3.2 locket-1.0.0 markdown-3.3.4 mccabe-0.6.1 multidict-6.0.2 nptyping-1.4.4 omegaconf-2.1.2 partd-1.2.0 portalocker-2.4.0 psutil-5.8.0 pyDeprecate-0.3.1 pycodestyle-2.8.0 pyflakes-2.4.0 pytorch-lightning-1.5.10 pyyaml-6.0 ray-1.8.0 redis-4.2.2 s3transfer-0.5.2 sacrebleu-2.0.0 sacremoses-0.0.49 scikit-image-0.19.2 scipy-1.7.3 sentencepiece-0.1.95 setuptools-59.5.0 timm-0.5.4 tokenizers-0.12.1 torchmetrics-0.7.3 transformers-4.16.2 typish-1.9.3 urllib3-1.25.11 xgboost-1.4.2 yacs-0.1.8 yarl-1.7.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (4.10.1)\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.13.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel) (1.5.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ipykernel) (21.3)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (1.0.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.8.0)\n",
            "Collecting jupyter-client>=6.1.12\n",
            "  Downloading jupyter_client-7.2.2-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.6/130.6 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.1.1)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (0.1.3)\n",
            "Collecting tornado>=6.1\n",
            "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.5/428.5 KB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython>=7.23.1\n",
            "  Downloading ipython-7.32.0-py3-none-any.whl (793 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.9/793.9 KB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (0.18.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (4.8.0)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.29-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.5/381.5 KB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (59.5.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel) (0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel) (4.9.2)\n",
            "Requirement already satisfied: pyzmq>=22.3 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel) (22.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->ipykernel) (3.0.8)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel) (0.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.15.0)\n",
            "Installing collected packages: tornado, prompt-toolkit, jupyter-client, ipython, ipykernel\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 5.3.5\n",
            "    Uninstalling jupyter-client-5.3.5:\n",
            "      Successfully uninstalled jupyter-client-5.3.5\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.13.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.32.0 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ipykernel-6.13.0 ipython-7.32.0 jupyter-client-7.2.2 prompt-toolkit-3.0.29 tornado-6.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GA4o7-me4eU"
      },
      "source": [
        "IMPORTANT: PLEASE READ BELOW INSTRUCTIONS\n",
        "\n",
        "MANUAL STEP: Restart Colab Runtime, then execute remaining cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHqLNcQUe8Ib"
      },
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import gc\n",
        "import math\n",
        "import os\n",
        "import glob"
      ],
      "metadata": {
        "id": "2GlmOcLQlqZJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/NASA PM_estimation/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e3yBc5YlveV",
        "outputId": "df53b4ac-7dcb-485c-b29e-5e9e27630360"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Data/datasets/Train.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "DxLzYe4aoay-",
        "outputId": "dc13a70e-0561-4d4c-eed3-f218cd1990ba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0    Unique    Id  Day        Lat         Lon   Elevation  \\\n",
              "0           1    1131_1  1131    1  36.840574 -121.366314  122.986002   \n",
              "1           2  1131_100  1131  100  36.840574 -121.366314  122.986002   \n",
              "2           3  1131_101  1131  101  36.840574 -121.366314  122.986002   \n",
              "3           4  1131_102  1131  102  36.840574 -121.366314  122.986002   \n",
              "4           5  1131_104  1131  104  36.840574 -121.366314  122.986002   \n",
              "\n",
              "   Emissions  Forest  Roads  ...  Plumes_Med  Plumes_Low  Max_Temp  Max_Wind  \\\n",
              "0        0.0       0    0.0  ...           0           0      53.4       5.3   \n",
              "1        0.0       0    0.0  ...           0           0      64.1       3.6   \n",
              "2        0.0       0    0.0  ...           0           0      62.7       5.1   \n",
              "3        0.0       0    0.0  ...           0           0      67.7       7.9   \n",
              "4        0.0       0    0.0  ...           0           0      60.1       6.5   \n",
              "\n",
              "   Precip  Rel_Humidity  Wind_Dir          BLH       AOD   PM  \n",
              "0     0.0          67.0     251.0   758.111816       NaN  3.7  \n",
              "1     0.0          48.0     308.0  1155.824219       NaN  2.6  \n",
              "2     0.0          64.0     200.0  1162.292725       NaN  2.9  \n",
              "3     0.0          68.0     221.0   263.273407       NaN  0.5  \n",
              "4     0.0          44.0     314.0  1268.919434  0.097667  2.4  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b371196-28f4-495f-8542-e191ffe23b6e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unique</th>\n",
              "      <th>Id</th>\n",
              "      <th>Day</th>\n",
              "      <th>Lat</th>\n",
              "      <th>Lon</th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Emissions</th>\n",
              "      <th>Forest</th>\n",
              "      <th>Roads</th>\n",
              "      <th>...</th>\n",
              "      <th>Plumes_Med</th>\n",
              "      <th>Plumes_Low</th>\n",
              "      <th>Max_Temp</th>\n",
              "      <th>Max_Wind</th>\n",
              "      <th>Precip</th>\n",
              "      <th>Rel_Humidity</th>\n",
              "      <th>Wind_Dir</th>\n",
              "      <th>BLH</th>\n",
              "      <th>AOD</th>\n",
              "      <th>PM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1131_1</td>\n",
              "      <td>1131</td>\n",
              "      <td>1</td>\n",
              "      <td>36.840574</td>\n",
              "      <td>-121.366314</td>\n",
              "      <td>122.986002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>53.4</td>\n",
              "      <td>5.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>251.0</td>\n",
              "      <td>758.111816</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1131_100</td>\n",
              "      <td>1131</td>\n",
              "      <td>100</td>\n",
              "      <td>36.840574</td>\n",
              "      <td>-121.366314</td>\n",
              "      <td>122.986002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64.1</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>308.0</td>\n",
              "      <td>1155.824219</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1131_101</td>\n",
              "      <td>1131</td>\n",
              "      <td>101</td>\n",
              "      <td>36.840574</td>\n",
              "      <td>-121.366314</td>\n",
              "      <td>122.986002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>62.7</td>\n",
              "      <td>5.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>1162.292725</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1131_102</td>\n",
              "      <td>1131</td>\n",
              "      <td>102</td>\n",
              "      <td>36.840574</td>\n",
              "      <td>-121.366314</td>\n",
              "      <td>122.986002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>67.7</td>\n",
              "      <td>7.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>263.273407</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1131_104</td>\n",
              "      <td>1131</td>\n",
              "      <td>104</td>\n",
              "      <td>36.840574</td>\n",
              "      <td>-121.366314</td>\n",
              "      <td>122.986002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>60.1</td>\n",
              "      <td>6.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>314.0</td>\n",
              "      <td>1268.919434</td>\n",
              "      <td>0.097667</td>\n",
              "      <td>2.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b371196-28f4-495f-8542-e191ffe23b6e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b371196-28f4-495f-8542-e191ffe23b6e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b371196-28f4-495f-8542-e191ffe23b6e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crossvalidate \n",
        "Make tables of crossvalidated predictions by station for various models \\\\\n",
        "\\\n",
        "Models chosen are those from Autogluon default: \\\\\n",
        "\\\n",
        "hyperparameters = {\n",
        "‘NN’: {}, ‘GBM’: [\n",
        "\n",
        "{}, {‘extra_trees’: True, ‘AG_args’: {‘name_suffix’: ‘XT’}},\n",
        "\n",
        "], ‘CAT’: {}, ‘RF’: [\n",
        "\n",
        "{‘criterion’: ‘gini’, ‘AG_args’: {‘name_suffix’: ‘Gini’, ‘problem_types’: [‘binary’, ‘multiclass’]}}, {‘criterion’: ‘entropy’, ‘AG_args’: {‘name_suffix’: ‘Entr’, ‘problem_types’: [‘binary’, ‘multiclass’]}}, {‘criterion’: ‘mse’, ‘AG_args’: {‘name_suffix’: ‘MSE’, ‘problem_types’: [‘regression’]}},\n",
        "\n",
        "], ‘XT’: [\n",
        "\n",
        "{‘criterion’: ‘gini’, ‘AG_args’: {‘name_suffix’: ‘Gini’, ‘problem_types’: [‘binary’, ‘multiclass’]}}, {‘criterion’: ‘entropy’, ‘AG_args’: {‘name_suffix’: ‘Entr’, ‘problem_types’: [‘binary’, ‘multiclass’]}}, {‘criterion’: ‘mse’, ‘AG_args’: {‘name_suffix’: ‘MSE’, ‘problem_types’: [‘regression’]}},\n",
        "\n",
        "], ‘KNN’: [\n",
        "\n",
        "{‘weights’: ‘uniform’, ‘AG_args’: {‘name_suffix’: ‘Unif’}}, {‘weights’: ‘distance’, ‘AG_args’: {‘name_suffix’: ‘Dist’}},\n",
        "\n",
        "], ‘custom’: [‘GBM’]\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "RTlMmgx5of4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cv(hyperparameters):\n",
        "  df['fold'] = np.random.randint(1, 11, df.shape[0]) # 10 fold random CV\n",
        "  n_fold = len(set(df['fold']))\n",
        "  print(n_fold) #should be 10\n",
        "  kf = GroupKFold(n_fold)\n",
        "  split = kf.split(df, groups = df['fold'])\n",
        "\n",
        "  metric_df = pd.DataFrame(columns = ['station', 'Day', 'PM', 'PM_pred', 'rmse', 'bias'])\n",
        "\n",
        "  for i, (train_idx, test_idx) in enumerate(split):\n",
        "    print(f'Starting training fold {i}.')\n",
        "    _ = gc.collect()\n",
        "\n",
        "    features = ['Day', 'Lat', 'Lon', 'Elevation', 'Emissions', 'Forest',\n",
        "        'Roads', 'Streets', 'Plumes_High', 'Plumes_Med', 'Plumes_Low',\n",
        "        'Max_Temp', 'Max_Wind', 'Precip', 'Rel_Humidity', 'Wind_Dir', 'BLH',\n",
        "        'AOD']\n",
        "    label_column = 'PM'\n",
        "\n",
        "    X = df[features]\n",
        "    y = df[label_column]\n",
        "\n",
        "    train_data = TabularDataset(pd.concat([X.loc[train_idx], y.loc[train_idx]], axis=1))\n",
        "    test_data = TabularDataset(pd.concat([X.loc[test_idx], y.loc[test_idx]], axis=1))\n",
        "\n",
        "    predictor = TabularPredictor(label=label_column, eval_metric='r2').fit(train_data=train_data, hyperparameters=hyperparameters)\n",
        "\n",
        "    y_test = test_data[label_column]\n",
        "\n",
        "    test_data_nolab = test_data.drop(labels = [label_column], axis = 1)\n",
        "\n",
        "    y_pred = predictor.predict(test_data_nolab)\n",
        "    \n",
        "    bias = y_pred-y_test\n",
        "    rmse = np.abs(bias)\n",
        "\n",
        "    station = np.repeat(df.loc[test_idx]['Id'].iloc[0], len(test_data['Day']))\n",
        "    df_to_append = pd.DataFrame({'station': station, 'Day': test_data['Day'], 'PM':y_test, 'PM_pred': y_pred, 'rmse': rmse, 'bias':bias})\n",
        "\n",
        "    metric_df = metric_df.append(df_to_append, ignore_index = True)\n",
        "\n",
        "  return metric_df"
      ],
      "metadata": {
        "id": "r6sTrlACoAPy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CAT = cv({'CAT': {}})\n",
        "CAT.to_csv(\"Data/output/CV_random/CAT.csv\", index = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOfycS6hsSTC",
        "outputId": "65c2acbc-89db-416d-d550-b1859ed15889"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "Starting training fold 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_231842/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_231842/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8851\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.79009, 7.75768)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12238.44 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.2s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7965, Val Rows: 886\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost ...\n",
            "\t0.7877\t = Validation score   (r2)\n",
            "\t123.46s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7877\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 123.89s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_231842/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_232046/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_232046/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8882\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.8018, 7.76379)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12134.54 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7993, Val Rows: 889\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost ...\n",
            "\t0.809\t = Validation score   (r2)\n",
            "\t122.54s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.809\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 122.85s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_232046/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_232249/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_232249/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8894\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.78025, 7.62626)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12106.16 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8004, Val Rows: 890\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost ...\n",
            "\t0.8323\t = Validation score   (r2)\n",
            "\t123.68s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8323\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 124.0s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_232249/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_232453/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_232453/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8903\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.84298, 7.80102)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12109.11 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8012, Val Rows: 891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost ...\n",
            "\t0.7727\t = Validation score   (r2)\n",
            "\t123.27s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7727\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 123.57s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_232453/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_232657/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_232657/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8904\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (108.6, 0.1, 8.79225, 7.38244)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12107.7 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 4.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8013, Val Rows: 891\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost ...\n",
            "\t0.8392\t = Validation score   (r2)\n",
            "\t122.92s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8392\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 123.24s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_232657/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_232900/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_232900/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8915\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.88372, 7.87341)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12104.76 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8023, Val Rows: 892\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 5.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.8251\t = Validation score   (r2)\n",
            "\t123.59s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8251\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 123.89s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_232900/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_233104/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_233104/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8924\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.8158, 7.79539)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12104.73 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8031, Val Rows: 893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 6.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost ...\n",
            "\t0.8173\t = Validation score   (r2)\n",
            "\t122.61s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8173\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 122.93s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_233104/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_233308/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_233308/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8940\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.83865, 7.82969)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12105.92 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 7.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8046, Val Rows: 894\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost ...\n",
            "\t0.8433\t = Validation score   (r2)\n",
            "\t111.61s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8433\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 111.9s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_233308/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_233500/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_233500/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8943\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.8036, 7.73232)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12104.3 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8048, Val Rows: 895\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost ...\n",
            "\t0.7946\t = Validation score   (r2)\n",
            "\t121.72s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7946\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 122.04s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_233500/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_233702/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_233702/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8944\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.82244, 7.69927)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12110.37 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 9.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8049, Val Rows: 895\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost ...\n",
            "\t0.773\t = Validation score   (r2)\n",
            "\t49.67s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.773\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 49.93s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_233702/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NN = cv({'NN': {}})\n",
        "NN.to_csv(\"Data/output/CV_random/NN.csv\", index = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVL0wMEc8PDR",
        "outputId": "78366744-145a-4a8b-fff6-82e669145dee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_233847/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_233847/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8849\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.80299, 7.72722)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "Starting training fold 0.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12094.79 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.16s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7964, Val Rows: 885\n",
            "\tWARNING: \"NN\" model has been deprecated in v0.4.0 and renamed to \"NN_MXNET\". Starting in v0.5.0, specifying \"NN\" or \"NN_MXNET\" will raise an exception. Consider instead specifying \"NN_TORCH\".\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\tWARNING: TabularNeuralNetMxnetModel (alias \"NN\" & \"NN_MXNET\") has been deprecated in v0.4.0.\n",
            "\t\tStarting in v0.5.0, calling TabularNeuralNetMxnetModel will raise an exception.\n",
            "\t\tConsider instead using TabularNeuralNetTorchModel via \"NN_TORCH\".\n",
            "\t0.6744\t = Validation score   (r2)\n",
            "\t114.67s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.6744\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 115.24s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_233847/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_234043/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_234043/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8853\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.83326, 7.71576)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11585.24 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7967, Val Rows: 886\n",
            "\tWARNING: \"NN\" model has been deprecated in v0.4.0 and renamed to \"NN_MXNET\". Starting in v0.5.0, specifying \"NN\" or \"NN_MXNET\" will raise an exception. Consider instead specifying \"NN_TORCH\".\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetMXNet ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training fold 1.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\t0.6572\t = Validation score   (r2)\n",
            "\t79.28s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.6572\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 79.76s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_234043/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_234203/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_234203/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8872\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.84812, 7.78869)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11756.85 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7984, Val Rows: 888\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training fold 2.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\tWARNING: \"NN\" model has been deprecated in v0.4.0 and renamed to \"NN_MXNET\". Starting in v0.5.0, specifying \"NN\" or \"NN_MXNET\" will raise an exception. Consider instead specifying \"NN_TORCH\".\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\t0.6126\t = Validation score   (r2)\n",
            "\t45.62s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.6126\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 46.1s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_234203/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_234249/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_234249/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8888\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.82267, 7.77644)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11750.19 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training fold 3.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7999, Val Rows: 889\n",
            "\tWARNING: \"NN\" model has been deprecated in v0.4.0 and renamed to \"NN_MXNET\". Starting in v0.5.0, specifying \"NN\" or \"NN_MXNET\" will raise an exception. Consider instead specifying \"NN_TORCH\".\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\t0.6561\t = Validation score   (r2)\n",
            "\t50.89s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.6561\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 51.37s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_234249/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_234341/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_234341/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8903\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.81469, 7.75579)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11750.42 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8012, Val Rows: 891\n",
            "\tWARNING: \"NN\" model has been deprecated in v0.4.0 and renamed to \"NN_MXNET\". Starting in v0.5.0, specifying \"NN\" or \"NN_MXNET\" will raise an exception. Consider instead specifying \"NN_TORCH\".\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training fold 4.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\t0.5221\t = Validation score   (r2)\n",
            "\t28.86s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5221\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 29.35s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_234341/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_234411/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_234411/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8936\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.80475, 7.67305)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11794.11 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8042, Val Rows: 894\n",
            "\tWARNING: \"NN\" model has been deprecated in v0.4.0 and renamed to \"NN_MXNET\". Starting in v0.5.0, specifying \"NN\" or \"NN_MXNET\" will raise an exception. Consider instead specifying \"NN_TORCH\".\n",
            "Fitting 1 L1 models ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training fold 5.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fitting model: NeuralNetMXNet ...\n",
            "\t0.6844\t = Validation score   (r2)\n",
            "\t64.57s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.6844\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 65.08s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_234411/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_234516/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_234516/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8940\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.78492, 7.59181)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12516.08 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training fold 6.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8046, Val Rows: 894\n",
            "\tWARNING: \"NN\" model has been deprecated in v0.4.0 and renamed to \"NN_MXNET\". Starting in v0.5.0, specifying \"NN\" or \"NN_MXNET\" will raise an exception. Consider instead specifying \"NN_TORCH\".\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\t0.6864\t = Validation score   (r2)\n",
            "\t66.52s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.6864\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 67.03s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_234516/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_234623/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_234623/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8942\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.83035, 7.81223)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12515.21 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training fold 7.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.12s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8047, Val Rows: 895\n",
            "\tWARNING: \"NN\" model has been deprecated in v0.4.0 and renamed to \"NN_MXNET\". Starting in v0.5.0, specifying \"NN\" or \"NN_MXNET\" will raise an exception. Consider instead specifying \"NN_TORCH\".\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\t0.6348\t = Validation score   (r2)\n",
            "\t60.94s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.6348\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 61.44s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_234623/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_234725/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_234725/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8958\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.85561, 7.88277)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12515.18 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.09s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8062, Val Rows: 896\n",
            "\tWARNING: \"NN\" model has been deprecated in v0.4.0 and renamed to \"NN_MXNET\". Starting in v0.5.0, specifying \"NN\" or \"NN_MXNET\" will raise an exception. Consider instead specifying \"NN_TORCH\".\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetMXNet ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training fold 8.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\t0.6455\t = Validation score   (r2)\n",
            "\t37.52s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.6455\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 37.96s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_234725/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_234803/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_234803/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8959\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (170.6, 0.1, 8.77485, 7.54417)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12514.37 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training fold 9.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8063, Val Rows: 896\n",
            "\tWARNING: \"NN\" model has been deprecated in v0.4.0 and renamed to \"NN_MXNET\". Starting in v0.5.0, specifying \"NN\" or \"NN_MXNET\" will raise an exception. Consider instead specifying \"NN_TORCH\".\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\t0.6636\t = Validation score   (r2)\n",
            "\t74.81s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.6636\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 75.28s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_234803/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GBM = cv({'GBM': {}})\n",
        "GBM.to_csv(\"Data/output/CV_random/GBM.csv\", index = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vs7qylX8TBL",
        "outputId": "3b7315d5-ddb2-4e0e-dbe7-57a874117755"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_235404/\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "Starting training fold 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_235404/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8848\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.82538, 7.71494)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12465.86 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.17s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7963, Val Rows: 885\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM ...\n",
            "\t0.7718\t = Validation score   (r2)\n",
            "\t7.35s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7718\t = Validation score   (r2)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 8.39s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_235404/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_235413/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_235413/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8871\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.78701, 7.72048)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12175.7 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.2s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.37s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7983, Val Rows: 888\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 8.50861\tvalid_set's r2: 0.800117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.8021\t = Validation score   (r2)\n",
            "\t8.84s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8021\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 10.24s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_235413/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_235424/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_235424/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8877\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.83753, 7.81792)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11974.63 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.2s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.31s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7989, Val Rows: 888\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 7.12128\tvalid_set's r2: 0.860418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.8642\t = Validation score   (r2)\n",
            "\t11.26s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8642\t = Validation score   (r2)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 12.49s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_235424/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_235437/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_235437/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8904\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.78231, 7.70126)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11667.26 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.18s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8013, Val Rows: 891\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 9.52059\tvalid_set's r2: 0.818894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.8228\t = Validation score   (r2)\n",
            "\t4.56s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8228\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 5.29s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_235437/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_235443/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_235443/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8904\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (108.6, 0.1, 8.78777, 7.32937)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11612.33 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 4.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8013, Val Rows: 891\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 8.95693\tvalid_set's r2: 0.860643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.86\t = Validation score   (r2)\n",
            "\t2.26s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.86\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 2.76s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_235443/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_235446/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_235446/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8908\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.80929, 7.75725)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11609.47 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 5.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8017, Val Rows: 891\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 11.0342\tvalid_set's r2: 0.77015\n",
            "[2000]\tvalid_set's l2: 10.6772\tvalid_set's r2: 0.776486\n",
            "[3000]\tvalid_set's l2: 10.5022\tvalid_set's r2: 0.781991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.7835\t = Validation score   (r2)\n",
            "\t6.74s\t = Training   runtime\n",
            "\t0.19s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7835\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 7.87s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_235446/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_235454/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_235454/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8920\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.85898, 7.83486)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11607.76 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8028, Val Rows: 892\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 6.\n",
            "[1000]\tvalid_set's l2: 25.1518\tvalid_set's r2: 0.737579\n",
            "[2000]\tvalid_set's l2: 24.0805\tvalid_set's r2: 0.747618\n",
            "[3000]\tvalid_set's l2: 24.0305\tvalid_set's r2: 0.75033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.7496\t = Validation score   (r2)\n",
            "\t7.28s\t = Training   runtime\n",
            "\t0.19s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7496\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 8.44s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_235454/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_235503/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_235503/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8924\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.80899, 7.78257)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11609.17 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 7.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8031, Val Rows: 893\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM ...\n",
            "\t0.8427\t = Validation score   (r2)\n",
            "\t1.72s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8427\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 2.11s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_235503/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_235505/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_235505/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8956\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.84307, 7.76679)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11608.16 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8060, Val Rows: 896\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 8.\n",
            "[1000]\tvalid_set's l2: 6.02935\tvalid_set's r2: 0.852862\n",
            "[2000]\tvalid_set's l2: 5.73312\tvalid_set's r2: 0.859973\n",
            "[3000]\tvalid_set's l2: 5.62252\tvalid_set's r2: 0.862773\n",
            "[4000]\tvalid_set's l2: 5.57903\tvalid_set's r2: 0.865696\n",
            "[5000]\tvalid_set's l2: 5.60014\tvalid_set's r2: 0.864838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.866\t = Validation score   (r2)\n",
            "\t10.04s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.866\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 11.66s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_235505/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220424_235518/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220424_235518/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8988\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.83128, 7.8337)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11607.04 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8089, Val Rows: 899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 9.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 8.21356\tvalid_set's r2: 0.80831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.8102\t = Validation score   (r2)\n",
            "\t2.52s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8102\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 3.05s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220424_235518/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RF = cv({'RF': {}})\n",
        "RF.to_csv(\"Data/output/CV_random/RF.csv\", index = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DltDkp3M8Wnk",
        "outputId": "46eb7c3b-462e-4f69-9329-db89caa97466"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_000340/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_000340/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8865\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.82962, 7.78289)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11766.61 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "Starting training fold 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7978, Val Rows: 887\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: RandomForest ...\n",
            "\t0.8047\t = Validation score   (r2)\n",
            "\t12.57s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8047\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 14.51s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_000340/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_000356/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_000356/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8869\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.8782, 7.78257)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11753.38 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7982, Val Rows: 887\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: RandomForest ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.7074\t = Validation score   (r2)\n",
            "\t12.93s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7074\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 14.66s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_000356/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_000411/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_000411/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8876\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.80362, 7.64351)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11750.5 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7988, Val Rows: 888\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: RandomForest ...\n",
            "\t0.7929\t = Validation score   (r2)\n",
            "\t13.04s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7929\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 14.73s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_000411/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_000426/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_000426/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8887\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.75553, 7.65507)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11749.06 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7998, Val Rows: 889\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: RandomForest ...\n",
            "\t0.7022\t = Validation score   (r2)\n",
            "\t13.05s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7022\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 14.71s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_000426/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_000442/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_000442/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8898\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.82109, 7.7802)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11749.24 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8008, Val Rows: 890\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: RandomForest ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 4.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.7582\t = Validation score   (r2)\n",
            "\t12.86s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7582\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 15.01s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_000442/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_000458/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_000458/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8929\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.81688, 7.79731)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11746.87 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.12s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8036, Val Rows: 893\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: RandomForest ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 5.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.711\t = Validation score   (r2)\n",
            "\t13.03s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.711\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 14.74s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_000458/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_000513/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_000513/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8939\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.85959, 7.85278)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11747.36 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 6.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8045, Val Rows: 894\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: RandomForest ...\n",
            "\t0.6942\t = Validation score   (r2)\n",
            "\t12.94s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.6942\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 14.83s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_000513/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_000529/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_000529/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8941\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.7733, 7.77313)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11746.76 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.12s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8046, Val Rows: 895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 7.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 1 L1 models ...\n",
            "Fitting model: RandomForest ...\n",
            "\t0.6866\t = Validation score   (r2)\n",
            "\t12.83s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.6866\t = Validation score   (r2)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 14.97s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_000529/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_000544/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_000544/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8945\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (170.6, 0.1, 8.82465, 7.51908)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11747.92 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8050, Val Rows: 895\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: RandomForest ...\n",
            "\t0.7123\t = Validation score   (r2)\n",
            "\t12.96s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7123\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 14.73s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_000544/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_000600/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_000600/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8951\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.80962, 7.68091)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11747.31 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8055, Val Rows: 896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 9.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 1 L1 models ...\n",
            "Fitting model: RandomForest ...\n",
            "\t0.8563\t = Validation score   (r2)\n",
            "\t13.05s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8563\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 14.86s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_000600/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "XT = cv({'XT': {}})\n",
        "XT.to_csv(\"Data/output/CV_random/XT.csv\", index = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XIx4oXm8aG5",
        "outputId": "63e04a2a-531b-4ea9-b860-706fc797b106"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_001218/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_001218/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8866\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.79383, 7.7627)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11745.8 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "Starting training fold 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.12s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7979, Val Rows: 887\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: ExtraTrees ...\n",
            "\t0.6699\t = Validation score   (r2)\n",
            "\t3.94s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.6699\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 5.71s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_001218/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_001225/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_001225/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8881\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.80962, 7.76257)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11745.18 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7992, Val Rows: 889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 1 L1 models ...\n",
            "Fitting model: ExtraTrees ...\n",
            "\t0.8255\t = Validation score   (r2)\n",
            "\t4.04s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8255\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 5.76s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_001225/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_001231/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_001231/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8891\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.79271, 7.60526)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11743.82 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8001, Val Rows: 890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 1 L1 models ...\n",
            "Fitting model: ExtraTrees ...\n",
            "\t0.7407\t = Validation score   (r2)\n",
            "\t4.34s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7407\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 6.19s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_001231/\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_001238/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_001238/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8893\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.85688, 7.87431)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11743.96 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.13s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8003, Val Rows: 890\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: ExtraTrees ...\n",
            "\t0.7345\t = Validation score   (r2)\n",
            "\t4.32s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7345\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 6.13s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_001238/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_001245/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_001245/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8909\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.8179, 7.7042)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11745.52 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 4.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.12s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8018, Val Rows: 891\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: ExtraTrees ...\n",
            "\t0.7702\t = Validation score   (r2)\n",
            "\t4.43s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7702\t = Validation score   (r2)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 6.71s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_001245/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_001253/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_001253/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8911\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (170.6, 0.1, 8.78521, 7.48668)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11744.44 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.13s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 5.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8019, Val Rows: 892\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: ExtraTrees ...\n",
            "\t0.7748\t = Validation score   (r2)\n",
            "\t4.26s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7748\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 6.28s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_001253/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_001300/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_001300/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8923\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.83311, 7.78094)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11742.95 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8030, Val Rows: 893\n",
            "Fitting 1 L1 models ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 6.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting model: ExtraTrees ...\n",
            "\t0.8167\t = Validation score   (r2)\n",
            "\t4.15s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8167\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 6.1s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_001300/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_001307/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_001307/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8926\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.84271, 7.82899)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11745.03 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.14s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 7.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8033, Val Rows: 893\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: ExtraTrees ...\n",
            "\t0.6347\t = Validation score   (r2)\n",
            "\t4.56s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.6347\t = Validation score   (r2)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 6.72s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_001307/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_001314/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_001314/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Data Rows:    8942\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.82815, 7.77626)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11745.18 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.14s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8047, Val Rows: 895\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: ExtraTrees ...\n",
            "\t0.7335\t = Validation score   (r2)\n",
            "\t4.33s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7335\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 6.3s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_001314/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_001321/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_001321/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8958\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.81162, 7.68406)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11742.72 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 9.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.18s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8062, Val Rows: 896\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: ExtraTrees ...\n",
            "\t0.796\t = Validation score   (r2)\n",
            "\t4.24s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.796\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 6.13s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_001321/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "KNN = cv({'KNN': {}})\n",
        "KNN.to_csv(\"Data/output/CV_random/KNN.csv\", index = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ArAPp4Z8dsW",
        "outputId": "29b34c1f-d339-4395-ba56-d31313b796b1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_002239/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_002239/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8873\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.82078, 7.78391)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11747.93 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "Starting training fold 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7985, Val Rows: 888\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: KNeighbors ...\n",
            "\t0.1707\t = Validation score   (r2)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.1707\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 0.47s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_002239/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_002240/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_002240/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8876\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.75564, 7.57814)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11748.62 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7988, Val Rows: 888\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: KNeighbors ...\n",
            "\t0.1833\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.1833\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 0.48s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_002240/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_002240-001/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_002240-001/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8896\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.84165, 7.6852)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11747.38 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8006, Val Rows: 890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 1 L1 models ...\n",
            "Fitting model: KNeighbors ...\n",
            "\t0.1538\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.1538\t = Validation score   (r2)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 0.5s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_002240-001/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_002241/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_002241/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8897\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.78953, 7.68881)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11746.18 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8007, Val Rows: 890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 1 L1 models ...\n",
            "Fitting model: KNeighbors ...\n",
            "\t0.1788\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.1788\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 0.48s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_002241/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_002242/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_002242/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8902\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.8027, 7.77237)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11746.99 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8011, Val Rows: 891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 4.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 1 L1 models ...\n",
            "Fitting model: KNeighbors ...\n",
            "\t0.0881\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.0881\t = Validation score   (r2)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 0.47s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_002242/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_002243/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_002243/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8912\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.82954, 7.74272)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11747.27 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8020, Val Rows: 892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 5.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 1 L1 models ...\n",
            "Fitting model: KNeighbors ...\n",
            "\t0.1821\t = Validation score   (r2)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.1821\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 0.47s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_002243/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_002243-001/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_002243-001/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8914\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (170.6, 0.1, 8.8457, 7.59831)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11746.45 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8022, Val Rows: 892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 6.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 1 L1 models ...\n",
            "Fitting model: KNeighbors ...\n",
            "\t0.1545\t = Validation score   (r2)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.1545\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 0.47s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_002243-001/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_002244/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_002244/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8917\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.82817, 7.79338)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11745.63 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8025, Val Rows: 892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 7.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 1 L1 models ...\n",
            "Fitting model: KNeighbors ...\n",
            "\t0.1071\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.1071\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 0.47s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_002244/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_002245/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_002245/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8946\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.8276, 7.75666)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11744.29 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8051, Val Rows: 895\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: KNeighbors ...\n",
            "\t0.1802\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.1802\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 0.49s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_002245/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_002246/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_002246/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8967\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.83025, 7.86752)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11744.84 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.12s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8070, Val Rows: 897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 9.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 1 L1 models ...\n",
            "Fitting model: KNeighbors ...\n",
            "\t0.113\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.113\t = Validation score   (r2)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 0.51s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_002246/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AutoGluon = cv('default')\n",
        "AutoGluon.to_csv(\"Data/output/CV_random/AutoGluon.csv\", index = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJdmFcCn8g8m",
        "outputId": "8aad6dec-2f1e-42ff-d66d-b35b4b976a43"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_002306/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_002306/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8852\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.868, 7.89958)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11744.15 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.27 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "Starting training fold 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7966, Val Rows: 886\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.1357\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.1465\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 20.811\tvalid_set's r2: 0.791245\n",
            "[2000]\tvalid_set's l2: 20.3251\tvalid_set's r2: 0.795398\n",
            "[3000]\tvalid_set's l2: 20.1436\tvalid_set's r2: 0.798475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.7988\t = Validation score   (r2)\n",
            "\t6.18s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 17.4957\tvalid_set's r2: 0.823328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.829\t = Validation score   (r2)\n",
            "\t2.23s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t0.738\t = Validation score   (r2)\n",
            "\t12.23s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.8123\t = Validation score   (r2)\n",
            "\t124.74s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t0.7364\t = Validation score   (r2)\n",
            "\t3.82s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.7372\t = Validation score   (r2)\n",
            "\t14.52s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.7077\t = Validation score   (r2)\n",
            "\t6.27s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.7506\t = Validation score   (r2)\n",
            "\t37.32s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.7881\t = Validation score   (r2)\n",
            "\t4.56s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8314\t = Validation score   (r2)\n",
            "\t0.31s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 218.35s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_002306/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_002645/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_002645/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8856\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.80193, 7.78414)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11483.27 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7970, Val Rows: 886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.0697\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.0809\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 20.5463\tvalid_set's r2: 0.761123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.7652\t = Validation score   (r2)\n",
            "\t3.51s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 19.2265\tvalid_set's r2: 0.776198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.7774\t = Validation score   (r2)\n",
            "\t3.41s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t0.6973\t = Validation score   (r2)\n",
            "\t12.23s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.7843\t = Validation score   (r2)\n",
            "\t125.54s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t0.6912\t = Validation score   (r2)\n",
            "\t3.94s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.7212\t = Validation score   (r2)\n",
            "\t7.33s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.7438\t = Validation score   (r2)\n",
            "\t8.05s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.7246\t = Validation score   (r2)\n",
            "\t42.93s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 22.7508\tvalid_set's r2: 0.735984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.7371\t = Validation score   (r2)\n",
            "\t4.52s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7992\t = Validation score   (r2)\n",
            "\t0.34s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 218.23s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_002645/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_003023/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_003023/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8902\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.81366, 7.76163)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11472.47 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8011, Val Rows: 891\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.2341\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.2296\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 11.6303\tvalid_set's r2: 0.797507\n",
            "[2000]\tvalid_set's l2: 10.6805\tvalid_set's r2: 0.812364\n",
            "[3000]\tvalid_set's l2: 10.5582\tvalid_set's r2: 0.815799\n",
            "[4000]\tvalid_set's l2: 10.5515\tvalid_set's r2: 0.816482\n",
            "[5000]\tvalid_set's l2: 10.5503\tvalid_set's r2: 0.814307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.817\t = Validation score   (r2)\n",
            "\t9.94s\t = Training   runtime\n",
            "\t0.27s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.8218\t = Validation score   (r2)\n",
            "\t1.63s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t0.7445\t = Validation score   (r2)\n",
            "\t12.43s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.8683\t = Validation score   (r2)\n",
            "\t126.34s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t0.7654\t = Validation score   (r2)\n",
            "\t3.92s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.6578\t = Validation score   (r2)\n",
            "\t7.52s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.8354\t = Validation score   (r2)\n",
            "\t22.03s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.7121\t = Validation score   (r2)\n",
            "\t41.78s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 11.4363\tvalid_set's r2: 0.801225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.8014\t = Validation score   (r2)\n",
            "\t6.34s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8683\t = Validation score   (r2)\n",
            "\t0.35s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 239.24s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_003023/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_003423/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_003423/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8903\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.83501, 7.70698)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11471.38 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.12s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8012, Val Rows: 891\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.1441\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.1547\t = Validation score   (r2)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 10.4716\tvalid_set's r2: 0.769599\n",
            "[2000]\tvalid_set's l2: 9.6924\tvalid_set's r2: 0.787498\n",
            "[3000]\tvalid_set's l2: 9.43439\tvalid_set's r2: 0.793881\n",
            "[4000]\tvalid_set's l2: 9.34752\tvalid_set's r2: 0.797143\n",
            "[5000]\tvalid_set's l2: 9.2591\tvalid_set's r2: 0.796149\n",
            "[6000]\tvalid_set's l2: 9.23123\tvalid_set's r2: 0.797904\n",
            "[7000]\tvalid_set's l2: 9.20435\tvalid_set's r2: 0.798851\n",
            "[8000]\tvalid_set's l2: 9.18818\tvalid_set's r2: 0.796986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.8\t = Validation score   (r2)\n",
            "\t15.07s\t = Training   runtime\n",
            "\t0.42s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 7.8946\tvalid_set's r2: 0.828297\n",
            "[2000]\tvalid_set's l2: 7.72447\tvalid_set's r2: 0.830807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.8326\t = Validation score   (r2)\n",
            "\t5.49s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t0.7265\t = Validation score   (r2)\n",
            "\t12.43s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.842\t = Validation score   (r2)\n",
            "\t124.91s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t0.7601\t = Validation score   (r2)\n",
            "\t3.81s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.6446\t = Validation score   (r2)\n",
            "\t7.29s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.8384\t = Validation score   (r2)\n",
            "\t13.38s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.649\t = Validation score   (r2)\n",
            "\t31.79s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 14.2503\tvalid_set's r2: 0.686461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.6904\t = Validation score   (r2)\n",
            "\t5.37s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8508\t = Validation score   (r2)\n",
            "\t0.36s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 227.92s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_003423/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_003812/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_003812/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8907\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.781, 7.75658)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11438.95 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8016, Val Rows: 891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 4.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.0719\t = Validation score   (r2)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.0813\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.8199\t = Validation score   (r2)\n",
            "\t1.73s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 8.9411\tvalid_set's r2: 0.836868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.8418\t = Validation score   (r2)\n",
            "\t2.29s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t0.8056\t = Validation score   (r2)\n",
            "\t12.25s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.7601\t = Validation score   (r2)\n",
            "\t2.19s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t0.8199\t = Validation score   (r2)\n",
            "\t4.12s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.7638\t = Validation score   (r2)\n",
            "\t7.21s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.7462\t = Validation score   (r2)\n",
            "\t2.11s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.747\t = Validation score   (r2)\n",
            "\t41.42s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.8508\t = Validation score   (r2)\n",
            "\t2.33s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8691\t = Validation score   (r2)\n",
            "\t0.33s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 81.21s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_003812/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_003934/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_003934/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8916\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.8368, 7.81107)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11422.82 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8024, Val Rows: 892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 5.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.1736\t = Validation score   (r2)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.1851\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 12.2004\tvalid_set's r2: 0.742543\n",
            "[2000]\tvalid_set's l2: 11.4764\tvalid_set's r2: 0.756466\n",
            "[3000]\tvalid_set's l2: 11.3374\tvalid_set's r2: 0.760231\n",
            "[4000]\tvalid_set's l2: 11.3056\tvalid_set's r2: 0.761966\n",
            "[5000]\tvalid_set's l2: 11.2677\tvalid_set's r2: 0.760954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.7636\t = Validation score   (r2)\n",
            "\t10.11s\t = Training   runtime\n",
            "\t0.27s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 9.10498\tvalid_set's r2: 0.807711\n",
            "[2000]\tvalid_set's l2: 8.68401\tvalid_set's r2: 0.814965\n",
            "[3000]\tvalid_set's l2: 8.75849\tvalid_set's r2: 0.8159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.8166\t = Validation score   (r2)\n",
            "\t7.02s\t = Training   runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t0.7573\t = Validation score   (r2)\n",
            "\t12.33s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.841\t = Validation score   (r2)\n",
            "\t126.59s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t0.7334\t = Validation score   (r2)\n",
            "\t4.02s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.7314\t = Validation score   (r2)\n",
            "\t7.55s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.8198\t = Validation score   (r2)\n",
            "\t7.54s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.6675\t = Validation score   (r2)\n",
            "\t55.46s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 8.0522\tvalid_set's r2: 0.829563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.8315\t = Validation score   (r2)\n",
            "\t6.64s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.848\t = Validation score   (r2)\n",
            "\t0.37s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 245.69s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_003934/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_004340/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_004340/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8916\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.80922, 7.70471)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11402.6 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.28 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 6.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8024, Val Rows: 892\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.0532\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.0302\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 10.8303\tvalid_set's r2: 0.694413\n",
            "[2000]\tvalid_set's l2: 10.6258\tvalid_set's r2: 0.701128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.7039\t = Validation score   (r2)\n",
            "\t3.8s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.7226\t = Validation score   (r2)\n",
            "\t1.42s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t0.6647\t = Validation score   (r2)\n",
            "\t12.43s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.7989\t = Validation score   (r2)\n",
            "\t125.69s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t0.6762\t = Validation score   (r2)\n",
            "\t3.92s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.6444\t = Validation score   (r2)\n",
            "\t7.25s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.7656\t = Validation score   (r2)\n",
            "\t8.79s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5521\t = Validation score   (r2)\n",
            "\t27.85s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.7378\t = Validation score   (r2)\n",
            "\t2.65s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8005\t = Validation score   (r2)\n",
            "\t0.33s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 199.85s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_004340/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_004701/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_004701/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8934\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (170.6, 0.1, 8.79434, 7.46822)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11400.77 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8040, Val Rows: 894\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 7.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.1048\t = Validation score   (r2)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.1226\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 26.8928\tvalid_set's r2: 0.673083\n",
            "[2000]\tvalid_set's l2: 25.5296\tvalid_set's r2: 0.68895\n",
            "[3000]\tvalid_set's l2: 25.0982\tvalid_set's r2: 0.694048\n",
            "[4000]\tvalid_set's l2: 24.867\tvalid_set's r2: 0.696782\n",
            "[5000]\tvalid_set's l2: 24.7213\tvalid_set's r2: 0.698945\n",
            "[6000]\tvalid_set's l2: 24.5957\tvalid_set's r2: 0.698765\n",
            "[7000]\tvalid_set's l2: 24.5591\tvalid_set's r2: 0.699902\n",
            "[8000]\tvalid_set's l2: 24.5453\tvalid_set's r2: 0.70053\n",
            "[9000]\tvalid_set's l2: 24.5181\tvalid_set's r2: 0.701328\n",
            "[10000]\tvalid_set's l2: 24.5039\tvalid_set's r2: 0.700418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.7021\t = Validation score   (r2)\n",
            "\t17.66s\t = Training   runtime\n",
            "\t0.57s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 20.4796\tvalid_set's r2: 0.749425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.7516\t = Validation score   (r2)\n",
            "\t2.39s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t0.6104\t = Validation score   (r2)\n",
            "\t12.43s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.7515\t = Validation score   (r2)\n",
            "\t125.21s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t0.6349\t = Validation score   (r2)\n",
            "\t3.92s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.5997\t = Validation score   (r2)\n",
            "\t7.62s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.7473\t = Validation score   (r2)\n",
            "\t6.68s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.6418\t = Validation score   (r2)\n",
            "\t33.75s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 22.1706\tvalid_set's r2: 0.728123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.7304\t = Validation score   (r2)\n",
            "\t5.3s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7614\t = Validation score   (r2)\n",
            "\t0.32s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 224.14s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_004701/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_005045/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_005045/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8949\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.83523, 7.64313)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11399.95 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8054, Val Rows: 895\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 8.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.0794\t = Validation score   (r2)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.0928\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 23.0924\tvalid_set's r2: 0.728313\n",
            "[2000]\tvalid_set's l2: 21.4207\tvalid_set's r2: 0.748375\n",
            "[3000]\tvalid_set's l2: 20.8853\tvalid_set's r2: 0.752665\n",
            "[4000]\tvalid_set's l2: 20.6945\tvalid_set's r2: 0.754253\n",
            "[5000]\tvalid_set's l2: 20.6366\tvalid_set's r2: 0.757115\n",
            "[6000]\tvalid_set's l2: 20.6134\tvalid_set's r2: 0.756899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.7571\t = Validation score   (r2)\n",
            "\t11.97s\t = Training   runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 21.6704\tvalid_set's r2: 0.741906\n",
            "[2000]\tvalid_set's l2: 21.1252\tvalid_set's r2: 0.750576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.7513\t = Validation score   (r2)\n",
            "\t4.36s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t0.6671\t = Validation score   (r2)\n",
            "\t12.33s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.7698\t = Validation score   (r2)\n",
            "\t124.63s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t0.6746\t = Validation score   (r2)\n",
            "\t3.91s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.7273\t = Validation score   (r2)\n",
            "\t7.16s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.774\t = Validation score   (r2)\n",
            "\t7.68s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.6274\t = Validation score   (r2)\n",
            "\t32.44s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 19.6729\tvalid_set's r2: 0.767428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.7682\t = Validation score   (r2)\n",
            "\t5.61s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7791\t = Validation score   (r2)\n",
            "\t0.34s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 217.86s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_005045/\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220425_005424/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220425_005424/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    8965\n",
            "Train Data Columns: 18\n",
            "Label Column: PM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (199.1, 0.1, 8.79708, 7.73206)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11398.13 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.29 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])   :  5 | ['Day', 'Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 13 | ['Lat', 'Lon', 'Elevation', 'Emissions', 'Roads', ...]\n",
            "\t\t('int', [])       :  1 | ['Day']\n",
            "\t\t('int', ['bool']) :  4 | ['Forest', 'Plumes_High', 'Plumes_Med', 'Plumes_Low']\n",
            "\t0.1s = Fit runtime\n",
            "\t18 features in original data used to generate 18 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.12s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8068, Val Rows: 897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training fold 9.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.1788\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.1709\t = Validation score   (r2)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 9.26583\tvalid_set's r2: 0.790092\n",
            "[2000]\tvalid_set's l2: 8.52056\tvalid_set's r2: 0.808072\n",
            "[3000]\tvalid_set's l2: 8.2473\tvalid_set's r2: 0.815069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.8162\t = Validation score   (r2)\n",
            "\t6.97s\t = Training   runtime\n",
            "\t0.19s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 6.84598\tvalid_set's r2: 0.845693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.8476\t = Validation score   (r2)\n",
            "\t2.85s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t0.7881\t = Validation score   (r2)\n",
            "\t12.23s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.8637\t = Validation score   (r2)\n",
            "\t124.34s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t0.7663\t = Validation score   (r2)\n",
            "\t3.92s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.6329\t = Validation score   (r2)\n",
            "\t7.34s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.8491\t = Validation score   (r2)\n",
            "\t14.01s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.598\t = Validation score   (r2)\n",
            "\t33.6s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's l2: 6.7624\tvalid_set's r2: 0.845632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.8492\t = Validation score   (r2)\n",
            "\t5.67s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8708\t = Validation score   (r2)\n",
            "\t0.34s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 217.85s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220425_005424/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Consolidate dataframes"
      ],
      "metadata": {
        "id": "dfIBsP5q8o_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_ids = pd.read_csv(\"Data/datasets/Small_Ids.csv\")['x']\n",
        "small_ids = [float(i) for i in small_ids]\n",
        "\n",
        "full_df = pd.DataFrame(columns = ['Model', 'test_area', 'station', 'Day', 'PM', 'PM_pred'])\n",
        "\n",
        "paths = glob.glob(\"Data/output/CV_random/*.csv\")\n",
        "\n",
        "for path in paths:\n",
        "  f = os.path.split(path)[1]\n",
        "  Model = os.path.splitext(f)[0]\n",
        "  Table = pd.read_csv(path)\n",
        "  Table['test_area'] = Table['station'].isin(small_ids)\n",
        "  Table['Model'] = Model\n",
        "\n",
        "  full_df = full_df.append(Table, ignore_index = True)\n",
        "\n",
        "full_df.to_csv(\"Data/output/all_cv_preds_random.csv\", index = False)"
      ],
      "metadata": {
        "id": "AssTiaqX8pZf"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}